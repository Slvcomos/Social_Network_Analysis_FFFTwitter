{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a931aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b77d27e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras import optimizers, utils, initializers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8fd9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import linkpred\n",
    "from linkpred.evaluation import Pair\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f08af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34e7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9390ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('universe_597.pickle', 'rb') as f:\n",
    "    universe_597 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc00d535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43365"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(universe_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16899a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_pickle_597 = pd.read_pickle('embedding_pickle_597.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70bc6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_597 = pd.read_pickle('edges_original_597.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28c978b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_597 = nx.read_graphml(\"H_597.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb20ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unconnected_pairs_597 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ddf98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_isequal(x, a, b):\n",
    "    if x[0] == a:\n",
    "        if x[1] == b:\n",
    "            return True\n",
    "    if x[1] == a:\n",
    "        if x[0] == b:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1061e2d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4241cb83422e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mui\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muniverse_597\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mis_not\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0medges_597\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_isequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mis_not\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ui in universe_597:\n",
    "    is_not = False\n",
    "    for i,j in edges_597.values:\n",
    "        if check_isequal(ui, i, j):\n",
    "            is_not = True\n",
    "            break\n",
    "    if not is_not:\n",
    "        all_unconnected_pairs_597.append((ui[0], ui[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5704a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_unconnected_pairs_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_597 = Word2Vec.load(\"word2vec_597.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d1ed9",
   "metadata": {},
   "source": [
    "Collegamenti inesistenti => target negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af89530",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_1_unlinked = [word2vec_597.wv[i[0]] for i in all_unconnected_pairs_597]\n",
    "node_2_unlinked = [word2vec_597.wv[i[1]] for i in all_unconnected_pairs_597]\n",
    "\n",
    "data_597 = pd.DataFrame({'node_1':node_1_unlinked, \n",
    "                     'node_2':node_2_unlinked})\n",
    "\n",
    "# add target variable 'link'\n",
    "data_597['link'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30068ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def omissibile_links(G, df_edges):\n",
    "    initial_node_count = len(G.nodes)\n",
    "\n",
    "    fb_df_temp = df_edges.copy()\n",
    "\n",
    "    # empty list to store removable links\n",
    "    omissible_links_index = []\n",
    "\n",
    "    for i in tqdm(df_edges.index.values):\n",
    "\n",
    "      # remove a node pair and build a new graph\n",
    "      G_temp = nx.from_pandas_edgelist(fb_df_temp.drop(index = i), \"first\", \"second\", create_using=nx.Graph())\n",
    "\n",
    "      # check there is no spliting of graph and number of nodes is same\n",
    "      if (nx.number_connected_components(G_temp) == 1) and (len(G_temp.nodes) == initial_node_count):\n",
    "        omissible_links_index.append(i)\n",
    "        fb_df_temp = fb_df_temp.drop(index = i)\n",
    "    return omissible_links_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "omissible_links_597 =  omissibile_links(H_597, edges_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ab9bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edges_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(omissible_links_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(universe_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd51a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of removable edges\n",
    "fb_df_ghost_597 = embedding_pickle_597.loc[omissible_links_597]\n",
    "\n",
    "fb_df_ghost_597 = fb_df_ghost_597.rename(columns={\"first\": \"node_1\", \"second\": \"node_2\"})\n",
    "# add the target variable 'link'\n",
    "fb_df_ghost_597['link'] = 1\n",
    "\n",
    "data_597 = data_597.append(fb_df_ghost_597[['node_1', 'node_2', 'link']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52701644",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_597['link'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb38d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_597.to_pickle(\"data_597.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef47ebb",
   "metadata": {},
   "source": [
    "----------------- Lettura dati -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca559161",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_597 = pd.read_pickle('data_597.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02860546",
   "metadata": {},
   "source": [
    "# 2 - Classificatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616eaf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_597 = []\n",
    "for i in range(data_597.shape[0]):\n",
    "    first = data_597.iloc[i][0]\n",
    "    second = data_597.iloc[i][1]\n",
    "    mixed = np.concatenate((first, second), 0)\n",
    "    X_597.append(mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246dd18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_597, xtest_597, ytrain_597, ytest_597 = train_test_split(np.asarray(X_597), data_597['link'], \n",
    "                                                test_size = 0.3, \n",
    "                                                random_state = 35,\n",
    "                                                stratify=data_597['link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe64ff9",
   "metadata": {},
   "source": [
    "### 1 - DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth': [2, 5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10, 20],\n",
    "}\n",
    "scores = ['roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bee94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtGridSearch( X_train, X_test, y_train, y_test, tuned_parameters, scores):\n",
    "    optimals = {}\n",
    "    for score in scores:\n",
    "        print(\"------- Score = \" + str(score) + \" ------- \\n\")\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "        k_fold = StratifiedKFold(n_splits=5, random_state=42)\n",
    "        \n",
    "        print(\"> Fold = \" + str(k_fold) + \"\\n\")\n",
    "        clf = GridSearchCV(model, tuned_parameters, error_score='raise', cv=5, scoring = score, return_train_score=True)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"> Best Parameter set: \\n\")\n",
    "        best = clf.best_params_\n",
    "        print(best)\n",
    "        \n",
    "        print(\"\\n> Grid scores:\\n\")\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        \n",
    "        parameters = {\"criterion\": [], \"max_depth\": [], \"min_samples_leaf\": [], \"min_samples_split\": []}\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "            parameters[\"criterion\"].append(params[\"criterion\"])\n",
    "\n",
    "            if(params[\"max_depth\"] == None):\n",
    "                parameters[\"max_depth\"].append(0)\n",
    "            else:\n",
    "                parameters[\"max_depth\"].append(params[\"max_depth\"])\n",
    "\n",
    "            #parameters[\"max_depth\"].append(params[\"max_depth\"])\n",
    "            parameters[\"min_samples_leaf\"].append(params[\"min_samples_leaf\"])\n",
    "            parameters[\"min_samples_split\"].append(params[\"min_samples_split\"])\n",
    "        \n",
    "        print(\"-> Report\\n\") \n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print(\"\\n\")\n",
    "        print(\"**** Matrice di Confusione *****\")\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        print(' True negative: %d False negative: %d' % (tn, fn))\n",
    "        print(' True positive: %d False positive: %d' % (tp, fp))\n",
    "\n",
    "        \n",
    "        # Creazione del csv\n",
    "        d = {score: means, 'std_dev': stds*2, 'criterion': parameters[\"criterion\"], \"max_depth\": parameters[\"max_depth\"], \"min_samples_leaf\": parameters[\"min_samples_leaf\"], \"min_samples_split\": parameters[\"min_samples_split\"]}\n",
    "        \n",
    "        dataF = pd.DataFrame(data=d)\n",
    "        \n",
    "        dataF.to_csv(\"result_DT_gridsearch.csv\",index=False, header=True)\n",
    "        \n",
    "\n",
    "        print(\"...........RESULTS FOR TRAINING.........\")\n",
    "        print(\"........................................\")\n",
    "        means = clf.cv_results_['mean_train_score']\n",
    "        stds = clf.cv_results_['std_train_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))        \n",
    "        \n",
    "        print(\"____________________________________________\")\n",
    "        \n",
    "        optimals[score] = best\n",
    "    return optimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d889752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimals_597 = builtGridSearch(xtrain_597, xtest_597, ytrain_597, ytest_597, tuned_parameters, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd61bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimals_597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_597 = tree.DecisionTreeClassifier(criterion = \"entropy\", max_depth = None, min_samples_leaf = 20, min_samples_split = 10)\n",
    "model_597.fit(xtrain_597, ytrain_597)\n",
    "y_pred_597 = model_597.predict(xtest_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_597 = model_597.predict_proba(xtest_597)\n",
    "fpr0, tpr0, _ = roc_curve(ytest_597, y_score_597[:, 1])\n",
    "roc_auc0_597 = auc(fpr0, tpr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f932b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr0, tpr0, color='darkorange', lw=3, label='$AUC_0$ = %.3f' % (roc_auc0_597))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e57596",
   "metadata": {},
   "source": [
    "### 1 - DecisionTree_Bilanciato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f5956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_n = data_597['link'].value_counts()[0] - data_597['link'].value_counts()[1]\n",
    "remove_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7299c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_597.copy()\n",
    "drop_indices = np.random.choice(df[df[\"link\"]==0].index, remove_n, replace=False)\n",
    "df_subset = df.drop(drop_indices)\n",
    "print(df_subset['link'].value_counts())\n",
    "\n",
    "X_sbset_597 = []\n",
    "for i in range(df_subset.shape[0]):\n",
    "    first = df_subset.iloc[i][0]\n",
    "    second = df_subset.iloc[i][1]\n",
    "    mixed = np.concatenate((first, second), 0)\n",
    "    X_sbset_597.append(mixed)\n",
    "    \n",
    "    \n",
    "xtrain_sb_597, xtest_sb_597, ytrain_sb_597, ytest_sb_597 = train_test_split(np.asarray(X_sbset_597), df_subset[\"link\"], \n",
    "                                                test_size = 0.3, \n",
    "                                                random_state = 35,\n",
    "                                                stratify=df_subset[\"link\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bf78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimals_sb_597 = builtGridSearch(xtrain_sb_597, xtest_sb_597, ytrain_sb_597, ytest_sb_597, tuned_parameters, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d7b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sb_597 = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = None, min_samples_leaf = 20, min_samples_split = 10)\n",
    "model_sb_597.fit(xtrain_sb_597, ytrain_sb_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_sb_597 = model_sb_597.predict_proba(xtest_sb_597)\n",
    "fpr0, tpr0, _ = roc_curve(ytest_sb_597, y_score_sb_597[:, 1])\n",
    "roc_auc0_dt_597_sb = auc(fpr0, tpr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1ee64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr0, tpr0, color='darkorange', lw=3, label='$AUC_0$ = %.3f' % (roc_auc0_dt_597_sb))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848bf159",
   "metadata": {},
   "source": [
    "### 2 - Regressione logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(xtrain_597, ytrain_597)\n",
    "predictions = lr.predict_proba(xtest_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eddcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = lr.predict_proba(xtest_597)\n",
    "fpr0, tpr0, _ = roc_curve(ytest_597, y_score[:, 1])\n",
    "roc_auc0 = auc(fpr0, tpr0)\n",
    "print(roc_auc0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr0, tpr0, color='darkorange', lw=3, label='$AUC_0$ = %.3f' % (roc_auc0))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da1989a",
   "metadata": {},
   "source": [
    "### 2 - Regressione Logistica_Bilanciata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(xtrain_sb_597, ytrain_sb_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3995aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = lr.predict_proba(xtest_sb_597)\n",
    "fpr0, tpr0, _ = roc_curve(ytest_sb_597, y_score[:, 1])\n",
    "roc_auc0 = auc(fpr0, tpr0)\n",
    "print(roc_auc0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db3b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr0, tpr0, color='darkorange', lw=3, label='$AUC_0$ = %.3f' % (roc_auc0))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3f677",
   "metadata": {},
   "source": [
    "### 3 - LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_xtrain_597, xval_597, new_ytrain_597, yval_597 = train_test_split(xtrain_597, ytrain_597, \n",
    "                                                test_size = 0.3, \n",
    "                                                random_state = 35,\n",
    "                                                stratify=ytrain_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a1ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2edbd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgbm.Dataset(new_xtrain_597, new_ytrain_597)\n",
    "test_data = lgbm.Dataset(xval_597, yval_597)\n",
    "\n",
    "# define parameters\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'num_threads' : 2,\n",
    "    'seed' : 76\n",
    "}\n",
    "\n",
    "# train lightGBM model\n",
    "model = lgbm.train(parameters,\n",
    "                   train_data,\n",
    "                   valid_sets=test_data,\n",
    "                   num_boost_round=1000,\n",
    "                   early_stopping_rounds=20)\n",
    "\n",
    "y_pred = model.predict(xtest_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e899c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr0, tpr0, _ = roc_curve(ytest_597, y_pred)\n",
    "roc_auc_lgbm = auc(fpr0, tpr0)\n",
    "print(roc_auc_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321376fe",
   "metadata": {},
   "source": [
    "### 3 - LGBM_Bilanciato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d0f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_xtrain_sb_597, xval_sb_597, new_ytrain_sb_597, yval_sb_597 = train_test_split(xtrain_sb_597, ytrain_sb_597, \n",
    "                                                test_size = 0.3, \n",
    "                                                random_state = 35,\n",
    "                                                stratify=ytrain_sb_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgbm.Dataset(new_xtrain_sb_597, new_ytrain_sb_597)\n",
    "test_data = lgbm.Dataset(xval_sb_597, yval_sb_597)\n",
    "\n",
    "# define parameters\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'false',\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'num_threads' : 2,\n",
    "    'seed' : 76\n",
    "}\n",
    "\n",
    "# train lightGBM model\n",
    "model = lgbm.train(parameters,\n",
    "                   train_data,\n",
    "                   valid_sets=test_data,\n",
    "                   num_boost_round=1000,\n",
    "                   early_stopping_rounds=20)\n",
    "y_pred = model.predict(xtest_sb_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12df862",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr0, tpr0, _ = roc_curve(ytest_sb_597, y_pred)\n",
    "roc_auc_lgbm_sb = auc(fpr0, tpr0)\n",
    "print(roc_auc_lgbm_sb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad1b35",
   "metadata": {},
   "source": [
    "### 3 - LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab462cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302475b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = {\n",
    "    'tol':(1.0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6),\n",
    "    'C': (0.001, 0.05, 0.01, 0.1, 1.0, 10.0, 50, 100.0)\n",
    "}\n",
    "# Set the parameters by cross-validation\n",
    "k_fold = StratifiedKFold(n_splits=4, random_state=42)\n",
    "\n",
    "scores = ['roc_auc']\n",
    "\n",
    "def gridsearch_linearsvc(X_train, y_train, X_test, y_test, k_fold, tuned_parameters, scores):\n",
    "    optimals = {}\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for ----> %s\" % score)\n",
    "        print()\n",
    "\n",
    "        svm = LinearSVC()\n",
    "\n",
    "        clf = GridSearchCV(svm, tuned_parameters, error_score='raise', cv=k_fold, scoring=score)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "        print(\"**** Matrice di Confusione *****\")\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        print(' True negative: %d False negative: %d' % (tn, fn))\n",
    "        print(' True positive: %d False positive: %d' % (tp, fp))\n",
    "        print(\"____________________________________________\")\n",
    "        optimals[score] = clf.best_params_\n",
    "    return optimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimals_597 = gridsearch_linearsvc(xtrain_597, ytrain_597, xtest_597, ytest_597, k_fold, tuned_parameters, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcebdeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimals_597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b32395",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_597 = LinearSVC(C = 100.0, tol =1.0)\n",
    "model_597.fit(xtrain_597, ytrain_597)\n",
    "\n",
    "\n",
    "y_score_597 = model_597.predict(xtest_597)\n",
    "\n",
    "cclf = CalibratedClassifierCV(base_estimator=model_597, cv=5)\n",
    "cclf.fit(xtrain_597, ytrain_597)\n",
    "y_pred = cclf.predict(xtest_597)\n",
    "y_score_597 = cclf.predict_proba(xtest_597)\n",
    "fpr0, tpr0, _ = roc_curve(ytest_597, y_score_597[:, 1])\n",
    "roc_auc0 = auc(fpr0, tpr0)\n",
    "print(roc_auc0)\n",
    "\n",
    "plt.plot(fpr0, tpr0, color='darkorange', lw=3, label='$AUC_0$ = %.3f' % (roc_auc0))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791beb8",
   "metadata": {},
   "source": [
    "### 3 - LinearSVC_Bilanciato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac9e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimals_sb_597 = gridsearch_linearsvc(xtrain_sb_597, ytrain_sb_597, xtest_sb_597, ytest_sb_597, k_fold, tuned_parameters, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd03af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimals_sb_597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sb_597 = LinearSVC(C = 10.0, tol =0.1)\n",
    "model_sb_597.fit(xtrain_sb_597, ytrain_sb_597)\n",
    "\n",
    "\n",
    "y_score_sb_597 = model_sb_597.predict(xtest_sb_597)\n",
    "\n",
    "cclf = CalibratedClassifierCV(base_estimator=model_sb_597, cv=5)\n",
    "cclf.fit(xtrain_sb_597, ytrain_sb_597)\n",
    "y_pred = cclf.predict(xtest_sb_597)\n",
    "y_score_sb_597 = cclf.predict_proba(xtest_sb_597)\n",
    "fpr0, tpr0, _ = roc_curve(ytest_sb_597, y_score_sb_597[:, 1])\n",
    "roc_auc0 = auc(fpr0, tpr0)\n",
    "print(roc_auc0)\n",
    "\n",
    "plt.plot(fpr0, tpr0, color='darkorange', lw=3, label='$AUC_0$ = %.3f' % (roc_auc0))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df1e242",
   "metadata": {},
   "source": [
    "# 4 - NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_1( X_train):\n",
    "    optimizer='adagrad'\n",
    "    #optimizer='adam'\n",
    "    n_feature = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=n_feature, activation='tanh'))\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    # Linear\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[\"AUC\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec95d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_2(X_train):\n",
    "    n_feature = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=n_feature, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    # Linear\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    sgd = optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=[\"AUC\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2620100",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_597 = build_model_1(xtrain_597)\n",
    "history1_597 = model1_597.fit(xtrain_597, ytrain_597, validation_data=(xtest_597, ytest_597), epochs=30, batch_size=10).history\n",
    "\n",
    "model2_597 = build_model_2(xtrain_597)\n",
    "history2_597 = model2_597.fit(xtrain_597, ytrain_597, validation_data=(xtest_597, ytest_597), epochs=30, batch_size=50).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70975dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1_597['loss'], label='Loss 10 (batch_size)')\n",
    "plt.plot(history2_597['loss'], label='Loss 50 (batch_size)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7cc970",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1_597['loss'], label='Train')\n",
    "plt.plot(history1_597['val_loss'], label='Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af4802",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2_597['loss'], label='Train')\n",
    "plt.plot(history2_597['val_loss'], label='Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50720034",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_1_597, test_auc_1_597 = model1_597.evaluate(xtest_597, ytest_597)\n",
    "test_loss_2_597, test_auc_2_597 = model2_597.evaluate(xtest_597, ytest_597)\n",
    "\n",
    "print('Loss %f, AUC %f' % (test_loss_1_597, test_auc_1_597))\n",
    "print('Loss %f, AUC %f' % (test_loss_2_597, test_auc_2_597))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3655f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, learning_rate=0.1, momentum = 0.9, nesterov = True,\n",
    "                 activation = 'sigmoid', regularizer = 0.01, units=3, hidden_layers=1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #initializer = initializers.RandomUniform(minval=0, maxval=0.5, seed=None)\n",
    "    model.add(Dense(units, input_dim=X_train.shape[1], activation = activation, \n",
    "                         kernel_regularizer=regularizers.l2(regularizer)))  \n",
    "    for i in range(1,hidden_layers):\n",
    "          model.add(Dense(units, activation = activation, \n",
    "                         kernel_regularizer=regularizers.l2(regularizer)))  \n",
    "    model.add(Dense(1, activation = 'sigmoid',  kernel_regularizer=regularizers.l2(regularizer)))\n",
    "    sgd = optimizers.SGD(learning_rate=learning_rate, momentum=momentum, nesterov=nesterov)\n",
    "    model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fcc2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = {'batch_size': [128],\n",
    "              'epochs': [100],\n",
    "             'learning_rate': [0.261],\n",
    "             'momentum':[0.9],\n",
    "             'nesterov':[False],\n",
    "             'activation':['tanh'],\n",
    "              'regularizer':[0.0001],\n",
    "              'units': [10],\n",
    "             'hidden_layers': [1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, loss = 0, accuracy = 0, batch_size = 0, epochs = 0, learning_rate=0, momentum=0,nesterov=False,\n",
    "                activation='sigmoid', regularizer=0, units=0):\n",
    "        self.accuracy_CV_list = []\n",
    "        self.accuracy = accuracy\n",
    "        self.loss_CV_list = []\n",
    "        self.loss = loss\n",
    "        self.mee_list = []\n",
    "        self.mee = 0\n",
    "        self.std = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.nesterov = nesterov\n",
    "        self.activation = activation\n",
    "        self.regularizer = regularizer\n",
    "        self.units = units\n",
    "        self.noise = 0\n",
    "    def toString(self):\n",
    "        print(\"\"\"{MEE: %f (+/- %0.2f), Number of Units: %d, Batch Size: %d, Epochs: %d, Learning Rate: %f, Momentum: %f,\n",
    "              \"Nesterov: %s, Activation: %s, Regularization: %f, Noise: %f}\"\"\" % \n",
    "              (self.mee, self.std, self.units, self.batch_size, self.epochs, self.learning_rate, self.momentum,\n",
    "              self.nesterov, self.activation, self.regularizer, self.noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearchNN(X_train, Y_train, parameters, cv = 3, rand=False):\n",
    "    models = []\n",
    "    allNames = list(parameters)\n",
    "    combinations = itertools.product(*(parameters[Name] for Name in allNames))\n",
    "    searchList = []\n",
    "    if rand:\n",
    "        searchList = random.sample(list(combinations), k=100)\n",
    "    else:\n",
    "        searchList = list(combinations)\n",
    "    for i in searchList:\n",
    "        print(searchList.index(i), i)\n",
    "        batch_size = i[0]\n",
    "        epochs=i[1]\n",
    "        learning_rate=i[2]\n",
    "        momentum=i[3]\n",
    "        nesterov=i[4]\n",
    "        activation=i[5]\n",
    "        regularizer=i[6]\n",
    "        units = i[7]\n",
    "        temp = Model(batch_size=batch_size, epochs=epochs, learning_rate=learning_rate,\n",
    "                     momentum=momentum, nesterov=nesterov, activation=activation, regularizer=regularizer, units=units)\n",
    "        model = None # Clearing the NN.\n",
    "        model = create_model(X_train, learning_rate=learning_rate, momentum=momentum, nesterov=nesterov, \n",
    "                                 activation=activation, regularizer=regularizer, units=units)\n",
    "        r = model.fit(X_train, Y_train,validation_split = float(1.0/cv),\n",
    "                      batch_size =batch_size, epochs=epochs, verbose=1)\n",
    "        loss = r.history['val_loss'][-1]\n",
    "        #accuracy = r.history['val_acc'][-1]\n",
    "        temp.loss = loss\n",
    "        #temp.accuracy = accuracy\n",
    "        models.append(temp) \n",
    "          \n",
    "    result = sorted(models, key=lambda x: x.loss, reverse=False)\n",
    "    return result, r, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7910cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allModels_597, r_597, model_597 = GridSearchNN(xtrain_597, ytrain_597, param_list, cv=3, rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecc5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_597 = model_597.predict_classes(xtest_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c2b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras_597 = model_597.predict(xtest_597).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(ytest_597, y_pred_keras_597)\n",
    "auc_keras_597 = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f40549",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras 597 (area = {:.3f})'.format(auc_keras_597))\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43603030",
   "metadata": {},
   "source": [
    "# 4 - NN_Bilanciato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b490fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_sb_597 = build_model_1(xtrain_sb_597)\n",
    "history1_sb_597 = model1_sb_597.fit(xtrain_sb_597, ytrain_sb_597, validation_data=(xtest_sb_597, ytest_sb_597), epochs=30, batch_size=10).history\n",
    "\n",
    "model2_sb_597 = build_model_2(xtrain_sb_597)\n",
    "history2_sb_597 = model2_sb_597.fit(xtrain_sb_597, ytrain_sb_597, validation_data=(xtest_sb_597, ytest_sb_597), epochs=30, batch_size=50).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fbd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_1_sb_597, test_auc_1_sb_597 = model1_sb_597.evaluate(xtest_sb_597, ytest_sb_597)\n",
    "test_loss_2_sb_597, test_auc_2_sb_597 = model2_sb_597.evaluate(xtest_sb_597, ytest_sb_597)\n",
    "\n",
    "print('Loss %f, AUC %f' % (test_loss_1_sb_597, test_auc_1_sb_597))\n",
    "print('Loss %f, AUC %f' % (test_loss_2_sb_597, test_auc_2_sb_597))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allModels_sb_597, r_sb_597, model_sb_597 = GridSearchNN(xtrain_sb_597, ytrain_sb_597, param_list, cv=3, rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f561d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sb_597 = model_sb_597.predict_classes(xtest_sb_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras_sb_597 = model_sb_597.predict(xtest_sb_597).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(ytest_sb_597, y_pred_keras_sb_597)\n",
    "auc_keras_sb_597 = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9756f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras bilancato 597 (area = {:.3f})'.format(auc_keras_sb_597))\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a35d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576a351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b6a6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a328e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed76ad63",
   "metadata": {},
   "source": [
    "# ----- Curve d'apprendimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6031fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes.set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes.set_ylim(*ylim)\n",
    "    axes.set_xlabel(\"Examples\")\n",
    "    axes.set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes.grid()\n",
    "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_dt(X1, y1, X2, y2):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "    estimator = tree.DecisionTreeClassifier(criterion = \"entropy\", max_depth = None, min_samples_leaf = 20, min_samples_split = 10)\n",
    "    title = \"Decision Tree G1\"\n",
    "    plot_learning_curve(estimator, title, X1, y1, axes=axes[0], ylim=(0.3, 1.01),\n",
    "                        cv=cv, n_jobs=10)\n",
    "    print(\"done\")\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "    estimator = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = None, min_samples_leaf = 20, min_samples_split = 10)\n",
    "    title = \"Decision Tree G1 Bilanciato\"\n",
    "    plot_learning_curve(estimator, title, X2, y2, axes=axes[1], ylim=(0.3, 1.01),\n",
    "                        cv=cv, n_jobs=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc3333",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_dt(xtrain_597, ytrain_597, xtrain_sb_597, ytrain_sb_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c6b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_regr(X1, y1, X2, y2):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "    estimator = LogisticRegression()\n",
    "    title = \"Logistic Regression 597\"\n",
    "    plot_learning_curve(estimator, title, X1, y1, axes=axes[0], ylim=(0.3, 1.01),\n",
    "                        cv=cv, n_jobs=10)\n",
    "\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "    estimator = LogisticRegression()\n",
    "    title = \"Logistic Regression 597 Bilanciato\"\n",
    "    plot_learning_curve(estimator, title, X2, y2, axes=axes[1], ylim=(0.3, 1.01),\n",
    "                        cv=cv, n_jobs=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb77f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_regr(xtrain_597, ytrain_597, xtrain_sb_597, ytrain_sb_597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804bc720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
