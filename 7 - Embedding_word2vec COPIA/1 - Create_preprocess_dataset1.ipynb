{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stackapi import StackAPI\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Preprocess meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Dati wiki/pulito_nodes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Significati</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fridaysforfuture</td>\n",
       "      <td>School Strike for Climate Swedish, also known ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climatestrike</td>\n",
       "      <td>School Strike for Climate Swedish, also known ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>climateaction</td>\n",
       "      <td>Climate action (or climate change action) refe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>climatecrisis</td>\n",
       "      <td>Climate crisis is a term describing global war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>climatechange</td>\n",
       "      <td>Contemporary climate change includes both glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>animals</td>\n",
       "      <td>Animals are multicellular, eukaryotic organism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>governo</td>\n",
       "      <td>Governo is a winemaking technique reportedly i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>emobility</td>\n",
       "      <td>EVs first came into existence in the mid-19th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>chile</td>\n",
       "      <td>Chile, officially the Republic of Chile, is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>onu</td>\n",
       "      <td>United Nations in other languages, e.g. French...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tag                                        Significati\n",
       "0   fridaysforfuture  School Strike for Climate Swedish, also known ...\n",
       "1      climatestrike  School Strike for Climate Swedish, also known ...\n",
       "2      climateaction  Climate action (or climate change action) refe...\n",
       "3      climatecrisis  Climate crisis is a term describing global war...\n",
       "4      climatechange   Contemporary climate change includes both glo...\n",
       "..               ...                                                ...\n",
       "94           animals  Animals are multicellular, eukaryotic organism...\n",
       "95           governo  Governo is a winemaking technique reportedly i...\n",
       "96         emobility  EVs first came into existence in the mid-19th ...\n",
       "97             chile  Chile, officially the Republic of Chile, is a ...\n",
       "98               onu  United Nations in other languages, e.g. French...\n",
       "\n",
       "[99 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = df['Tag']\n",
    "meaning = df['Significati']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(corpus):\n",
    "    clear_text = []\n",
    "    for phrase in corpus:\n",
    "        # Replace URL with the tag url\n",
    "        phrase = re.sub(\"https*\\S+\", \"url\", phrase)\n",
    "        # Remove strange characters\n",
    "        # &quot => \"\"\n",
    "        # &#39 => '\n",
    "        # &amp; => &\n",
    "        # &lt; => <\n",
    "        # &gt; => >\n",
    "        phrase = re.sub(\"&quot;|\\r|\\n\\|&#39|&amp;|&lt;|&gt;\", \"\", phrase)\n",
    "\n",
    "        # Punctuaction removal\n",
    "        phrase = re.sub('[%s]' % re.escape(string.punctuation), ' ', phrase)\n",
    "        # Replace numbers with the tag number\n",
    "        phrase = re.sub(\"\\d+\", \"number \", phrase)\n",
    "        # Convert to lowercase\n",
    "        phrase = phrase.lower()\n",
    "        # Replace the over spaces\n",
    "        phrase = re.sub('\\s{2,}', \" \", phrase)\n",
    "        clear_text.append([phrase])\n",
    "    return clear_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_text = clean_text(meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import itertools\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_graphml(\"../DataSet FFF/Graph_data/Real_Network.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_dict = dict(G.degree(G.nodes()))\n",
    "nx.set_node_attributes(G, degree_dict, 'degree')\n",
    "sorted_degree = sorted(degree_dict.items(), key = itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n"
     ]
    }
   ],
   "source": [
    "sample_nodes_597 = []\n",
    "for i in sorted_degree:\n",
    "    if i[1] > 50:\n",
    "        sample_nodes_597.append(i[0])\n",
    "print(len(sample_nodes_597))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n"
     ]
    }
   ],
   "source": [
    "sample_nodes_1057 = []\n",
    "for i in sorted_degree:\n",
    "    if i[1] > 30:\n",
    "        sample_nodes_1057.append(i[0])\n",
    "print(len(sample_nodes_1057))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sample_meaning(sample, meaning):\n",
    "    sampled_meaning = []\n",
    "    sample_nodes = []\n",
    "    for i in sample:\n",
    "        for j in range(len(tags)):\n",
    "            if tags[j]==i:\n",
    "                sampled_meaning.append(i + \" \" + meaning[j][0])\n",
    "                sample_nodes.append(i)\n",
    "    return sampled_meaning, sample_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_meaning_597, sample_nodes_597 = select_sample_meaning(sample_nodes_597, cleared_text)\n",
    "sampled_meaning_1057, sample_nodes_1057 = select_sample_meaning(sample_nodes_1057, cleared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(sample_nodes_1057)):\\n    if not isNaN(tags[i]):\\n        sampled_meaning_1057[i] = sample_nodes_1057[i] + \" \" + sampled_meaning_1057[i][0]\\n    else:\\n        sampled_meaning_1057[i] = \"nan \" + sampled_meaning_1057[i][0]\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in range(len(sample_nodes_1057)):\n",
    "    if not isNaN(tags[i]):\n",
    "        sampled_meaning_1057[i] = sample_nodes_1057[i] + \" \" + sampled_meaning_1057[i][0]\n",
    "    else:\n",
    "        sampled_meaning_1057[i] = \"nan \" + sampled_meaning_1057[i][0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = []\n",
    "for phrase in sampled_meaning_597:\n",
    "    word_tokens.append(phrase.split())\n",
    "stop_words = stopwords.words('english')\n",
    "no_sw_597=[]\n",
    "for phrase in word_tokens:\n",
    "    no_sw_tmp=[]\n",
    "    for word in phrase:\n",
    "        if word not in stop_words:\n",
    "            no_sw_tmp.append(word)\n",
    "    no_sw_597.append(no_sw_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = []\n",
    "for phrase in sampled_meaning_1057:\n",
    "    word_tokens.append(phrase.split())\n",
    "stop_words = stopwords.words('english')\n",
    "no_sw_1057=[]\n",
    "for phrase in word_tokens:\n",
    "    no_sw_tmp=[]\n",
    "    for word in phrase:\n",
    "        if word not in stop_words:\n",
    "            no_sw_tmp.append(word)\n",
    "    no_sw_1057.append(no_sw_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_meaning_597 = []\n",
    "for i in no_sw_597:\n",
    "    new_s = \"\"\n",
    "    for j in i:\n",
    "        new_s = new_s + \" \" + j\n",
    "    cleared_meaning_597.append(new_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_meaning_1057 = []\n",
    "for i in no_sw_1057:\n",
    "    new_s = \"\"\n",
    "    for j in i:\n",
    "        new_s = new_s + \" \" + j\n",
    "    cleared_meaning_1057.append(new_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Tags\": sample_nodes_597, \"Meaning\" : cleared_meaning_597})\n",
    "df.to_csv(\"nodes_597_meaning.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Tags\": sample_nodes_1057, \"Meaning\" : cleared_meaning_1057})\n",
    "df.to_csv(\"nodes_1057_meaning.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_597 = Word2Vec(no_sw_597, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1323"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec_597.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_isin(word2vec, data):\n",
    "    not_in = []\n",
    "    for i in data:\n",
    "        try:\n",
    "            word2vec.wv[i]\n",
    "        except:\n",
    "            not_in.append(i)\n",
    "    print(len(not_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_1057 = Word2Vec(no_sw_1057, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1538"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec_1057.wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Store word2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linkpred.evaluation import Pair\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_597 = G.subgraph(sample_nodes_597)\n",
    "H_1057 = G.subgraph(sample_nodes_1057)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = []\n",
    "second = []\n",
    "for i in H_597.edges():\n",
    "    first.append(word2vec_597.wv[i[0]])\n",
    "    second.append(word2vec_597.wv[i[1]])\n",
    "new_df = pd.DataFrame({\"first\":first, \"second\":second})\n",
    "new_df.reset_index(inplace=True, drop=True)\n",
    "new_df.to_pickle(\"embedding_pickle_597.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = []\n",
    "second = []\n",
    "for i in H_1057.edges():\n",
    "    first.append(word2vec_1057.wv[i[0]])\n",
    "    second.append(word2vec_1057.wv[i[1]])\n",
    "new_df = pd.DataFrame({\"first\":first, \"second\":second})\n",
    "new_df.reset_index(inplace=True, drop=True)\n",
    "new_df.to_pickle(\"embedding_pickle_1057.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_597.save(\"word2vec_597.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_1057.save(\"word2vec_1057.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(H_597.nodes())\n",
    "universe_597 = set([Pair(i) for i in itertools.product(nodes, nodes) if i[0]!=i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(H_1057.nodes())\n",
    "universe_1057 = set([Pair(i) for i in itertools.product(nodes, nodes) if i[0]!=i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('universe_1057.pickle', 'wb') as f:\n",
    "    pickle.dump(universe_1057, f)\n",
    "with open('universe_597.pickle', 'wb') as f:\n",
    "    pickle.dump(universe_597, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = []\n",
    "second = []\n",
    "for i in H_597.edges():\n",
    "    first.append(i[0])\n",
    "    second.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({\"first\":first, \"second\":second})\n",
    "new_df.reset_index(inplace=True, drop=True)\n",
    "new_df.to_pickle(\"edges_original_597.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = []\n",
    "second = []\n",
    "for i in H_1057.edges():\n",
    "    first.append(i[0])\n",
    "    second.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({\"first\":first, \"second\":second})\n",
    "new_df.reset_index(inplace=True, drop=True)\n",
    "new_df.to_pickle(\"edges_original_1057.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(H_597,\"H_597.graphml\")\n",
    "nx.write_graphml(H_1057,\"H_1057.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
